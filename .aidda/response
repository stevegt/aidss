File: /home/stevegt/lab/aidss/cmd/aidss/main.go
```go
package main

import (
	"context"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"strings"
	"sync"

	"github.com/fsnotify/fsnotify"
	"github.com/google/uuid"
	"github.com/spf13/cobra"
	"rsc.io/pdf"

	"github.com/stevegt/aidss/llm"

	. "github.com/stevegt/goadapt"
)

var (
	watchPath string
	modelName string
	client    llm.Client
	mutex     sync.Mutex // To handle concurrent access

	promptFn   = "prompt.txt"
	responseFn = "response.txt"
)

func main() {
	// Initialize and register providers
	llm.RegisterProviders()

	// Get available models from llm package
	models := llm.Models()

	// Initialize the command-line interface
	rootCmd := &cobra.Command{
		Use:   "decision_tool",
		Short: "Decision Support Tool",
		Run: func(cmd *cobra.Command, args []string) {
			startDaemon()
		},
	}

	// Make sure usage includes model names
	modelUsage := fmt.Sprintf("Model to use (%s)", strings.Join(models, ", "))

	// Define flags
	rootCmd.Flags().StringVarP(&watchPath, "path", "p", ".", "Path to watch")
	rootCmd.Flags().StringVarP(&modelName, "model", "m", models[0], modelUsage)

	// Execute the root command
	if err := rootCmd.Execute(); err != nil {
		log.Fatal(err)
	}
}

// startDaemon starts the decision tool daemon. The daemon watches the file system for changes
// and responds to user messages and attachments.
func startDaemon() {
	var err error

	// Set up the LLM client based on the model name
	client, err = llm.NewClient(modelName)
	if err != nil {
		log.Fatal(err)
	}

	// Start the file watcher
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		log.Fatal(err)
	}
	defer watcher.Close()

	done := make(chan bool)

	// Handle file system events
	go func() {
		for {
			select {
			case event, ok := <-watcher.Events:
				if !ok {
					// Watcher has been closed
					return
				}
				if event.Op&fsnotify.Write == fsnotify.Write {
					// handle file write events
					if filepath.Base(event.Name) == promptFn {
						log.Println("Detected change in:", event.Name)
						handleUserMessage(filepath.Dir(event.Name))
					}
					if filepath.Ext(event.Name) == ".pdf" {
						log.Println("Detected PDF attachment:", event.Name)
						handlePDFAttachment(event.Name, extractTextFromPDF)
					}
				}
				if event.Op&fsnotify.Create == fsnotify.Create {
					// If a new directory is created, add it to the watcher
					fi, err := os.Stat(event.Name)
					if err == nil && fi.IsDir() {
						watcher.Add(event.Name)
						log.Println("Added new directory to watcher:", event.Name)
					}
				}
			case err, ok := <-watcher.Errors:
				if !ok {
					return
				}
				log.Println("error:", err)
			}
		}
	}()

	// Watch the root path
	err = addWatcherRecursive(watcher, watchPath)
	if err != nil {
		log.Fatal(err)
	}

	log.Println("Started watching:", watchPath)
	<-done
}

// addWatcherRecursive recursively adds a directory and its subdirectories to the watcher
func addWatcherRecursive(watcher *fsnotify.Watcher, path string) error {
	err := watcher.Add(path)
	if err != nil {
		return err
	}

	files, err := ioutil.ReadDir(path)
	if err != nil {
		return err
	}

	for _, file := range files {
		if file.IsDir() {
			err = addWatcherRecursive(watcher, filepath.Join(path, file.Name()))
			if err != nil {
				return err
			}
		}
	}

	return nil
}

// handleUserMessage handles a user message by generating a response from the language model
func handleUserMessage(path string) {
	mutex.Lock()
	defer mutex.Unlock()

	messagePath := filepath.Join(path, promptFn)
	message, err := ioutil.ReadFile(messagePath)
	if err != nil {
		log.Println("Error reading user message:", err)
		return
	}

	// Build context messages
	contextMessages := buildContextMessages(path)

	// Append the new message
	contextMessages = append(contextMessages, llm.Message{
		Role:    llm.ChatMessageRoleUser,
		Content: string(message),
	})

	// Check if any attachments need to be included
	attachmentsContent, err := getAttachmentsContent(path)
	if err != nil {
		log.Println("Error reading attachments:", err)
		return
	}

	if attachmentsContent != "" {
		// Add the attachments content to the system prompt
		contextMessages = append([]llm.Message{
			{
				Role:    llm.ChatMessageRoleSystem,
				Content: "The following attachments are included:\n" + attachmentsContent,
			},
		}, contextMessages...)
	}

	response, err := getLLMResponse(contextMessages)
	if err != nil {
		log.Println("Error getting LLM response:", err)
		return
	}

	responsePath := filepath.Join(path, responseFn)
	err = ioutil.WriteFile(responsePath, []byte(response), 0644)
	if err != nil {
		log.Println("Error writing LLM response:", err)
	}

	log.Println("LLM response written to:", responsePath)
}

// buildContextMessages builds a list of chat messages from the root to the current directory
// to provide context to the language model
func buildContextMessages(path string) []llm.Message {
	var messages []llm.Message
	var paths []string

	// Collect paths from root to current directory
	currentPath := path
	for {
		paths = append([]string{currentPath}, paths...)
		parentPath := filepath.Dir(currentPath)
		if parentPath == currentPath || parentPath == "." {
			break
		}
		currentPath = parentPath
	}

	// Build messages from collected paths
	for _, p := range paths {
		if content, err := ioutil.ReadFile(filepath.Join(p, promptFn)); err == nil {
			messages = append(messages, llm.Message{
				Role:    llm.ChatMessageRoleUser,
				Content: string(content),
			})
		}
		if content, err := ioutil.ReadFile(filepath.Join(p, responseFn)); err == nil {
			messages = append(messages, llm.Message{
				Role:    llm.ChatMessageRoleAssistant,
				Content: string(content),
			})
		}
	}

	return messages
}

func getAttachmentsContent(path string) (string, error) {
	var contentBuilder strings.Builder

	files, err := ioutil.ReadDir(path)
	if err != nil {
		return "", err
	}

	for _, file := range files {
		if strings.HasSuffix(file.Name(), ".pdf.txt") {
			attachmentContent, err := ioutil.ReadFile(filepath.Join(path, file.Name()))
			if err != nil {
				return "", err
			}
			contentBuilder.WriteString("Attachment: " + file.Name() + "\n")
			contentBuilder.WriteString(string(attachmentContent) + "\n")
		}
	}

	return contentBuilder.String(), nil
}

func getLLMResponse(messages []llm.Message) (string, error) {
	ctx := context.Background()
	response, err := client.GenerateResponse(ctx, messages)
	if err != nil {
		return "", err
	}
	return response, nil
}

func handlePDFAttachment(pdfPath string, extractTextFunc func(string) (string, error)) {
	mutex.Lock()
	defer mutex.Unlock()

	text, err := extractTextFunc(pdfPath)
	if err != nil {
		log.Println("Error extracting text from PDF:", err)
		return
	}

	// Save extracted text alongside the PDF
	txtPath := pdfPath + ".txt"
	err = ioutil.WriteFile(txtPath, []byte(text), 0644)
	if err != nil {
		log.Println("Error writing extracted text:", err)
		return
	}

	log.Println("Extracted text from PDF saved to:", txtPath)
}

func extractTextFromPDF(pdfPath string) (string, error) {
	r, err := pdf.Open(pdfPath)
	if err != nil {
		return "", err
	}
	var text strings.Builder
	numPages := r.NumPage()
	for i := 1; i <= numPages; i++ {
		p := r.Page(i)
		if p.V.IsNull() {
			continue
		}
		content := p.Content()
		for _, txt := range content.Text {
			text.WriteString(txt.S + " ")
		}
	}
	return text.String(), nil
}

func createNewDecisionNode(parentPath, descriptor string) (string, error) {
	// Sanitize the descriptor to remove invalid characters
	sanitizedDescriptor := sanitizeDescriptor(descriptor)

	// Generate a unique identifier
	uuidStr := generateUUID()

	// Combine to create the directory name
	dirName := fmt.Sprintf("%s_%s", sanitizedDescriptor, uuidStr)
	newPath := filepath.Join(parentPath, dirName)

	err := os.Mkdir(newPath, 0755)
	if err != nil {
		return "", err
	}
	return newPath, nil
}

func sanitizeDescriptor(descriptor string) string {
	// Replace spaces with underscores, remove special characters
	descriptor = strings.ReplaceAll(descriptor, " ", "_")
	descriptor = strings.ReplaceAll(descriptor, "/", "_")
	descriptor = strings.ReplaceAll(descriptor, "\\", "_")
	// Add more replacements as needed
	return descriptor
}

func generateUUID() string {
	// Generate a UUID
	id := uuid.New()
	return id.String()
}

func summarizePath(path string) {
	mutex.Lock()
	defer mutex.Unlock()

	messages := buildContextMessages(path)
	var textBuilder strings.Builder
	for _, msg := range messages {
		textBuilder.WriteString(msg.Role + ": " + msg.Content + "\n")
	}
	text := textBuilder.String()

	summary, err := getSummary(text)
	if err != nil {
		log.Println("Error summarizing path:", err)
		return
	}

	summaryPath := filepath.Join(path, "summary.txt")
	err = ioutil.WriteFile(summaryPath, []byte(summary), 0644)
	if err != nil {
		log.Println("Error writing summary:", err)
	} else {
		log.Println("Summary written to:", summaryPath)
	}
}

func getSummary(text string) (string, error) {
	summaryPrompt := fmt.Sprintf("Please provide a concise summary of the following conversation:\n\n%s", text)
	messages := []llm.Message{
		{
			Role:    llm.ChatMessageRoleUser,
			Content: summaryPrompt,
		},
	}
	return getLLMResponse(messages)
}

func updateMetrics(path string, metrics map[string]interface{}) {
	metricsPath := filepath.Join(path, "metrics.json")
	data, err := json.MarshalIndent(metrics, "", "  ")
	if err != nil {
		log.Println("Error marshalling metrics:", err)
		return
	}
	err = ioutil.WriteFile(metricsPath, data, 0644)
	if err != nil {
		log.Println("Error writing metrics:", err)
	} else {
		log.Println("Metrics updated at:", metricsPath)
	}
}
```
EOF_/home/stevegt/lab/aidss/cmd/aidss/main.go

File: /home/stevegt/lab/aidss/cmd/aidss/main_test.go
```go
package main

import (
	"encoding/json"
	"io/ioutil"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"testing"

	"github.com/fsnotify/fsnotify"
	"github.com/stevegt/aidss/llm"
)

func init() {
	// Initialize and register providers for testing
	llm.RegisterProvider("mock", llm.NewMockProvider())
}

func TestCreateNewDecisionNode(t *testing.T) {
	parentDir, err := ioutil.TempDir("", "test_decision_node")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(parentDir)

	descriptor := "Test Node"
	newPath, err := createNewDecisionNode(parentDir, descriptor)
	if err != nil {
		t.Fatalf("Expected no error, got %v", err)
	}

	if _, err := os.Stat(newPath); os.IsNotExist(err) {
		t.Fatalf("Expected directory %s to be created", newPath)
	}

	expectedPrefix := filepath.Join(parentDir, "Test_Node_")
	if !strings.HasPrefix(newPath, expectedPrefix) {
		t.Errorf("Expected directory name to start with %s, got %s", expectedPrefix, newPath)
	}
}

func TestHandleUserMessage(t *testing.T) {
	// Set up temporary directory
	tempDir, err := ioutil.TempDir("", "test_user_message")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(tempDir)

	// Create prompt.txt
	messageContent := "Test message"
	err = ioutil.WriteFile(filepath.Join(tempDir, "prompt.txt"), []byte(messageContent), 0644)
	if err != nil {
		t.Fatal(err)
	}

	// Create the mock client
	var errClient error
	client, errClient = llm.NewClient("mock-model")
	if errClient != nil {
		t.Fatalf("Error creating mock client: %v", errClient)
	}

	// Mock mutex
	mutex = sync.Mutex{}

	// Call handleUserMessage
	handleUserMessage(tempDir)

	// Check response.txt
	responsePath := filepath.Join(tempDir, "response.txt")
	data, err := ioutil.ReadFile(responsePath)
	if err != nil {
		t.Fatalf("Expected response.txt to be created, got error: %v", err)
	}

	if string(data) != "This is a mock response." {
		t.Errorf("Expected 'This is a mock response.', got '%s'", string(data))
	}
}

func TestBuildContextMessages(t *testing.T) {
	// Set up nested directories
	rootDir, err := ioutil.TempDir("", "test_context_messages")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(rootDir)

	subDir := filepath.Join(rootDir, "subdir")
	err = os.Mkdir(subDir, 0755)
	if err != nil {
		t.Fatal(err)
	}

	// Create prompt.txt and response.txt in root
	err = ioutil.WriteFile(filepath.Join(rootDir, "prompt.txt"), []byte("Root message"), 0644)
	if err != nil {
		t.Fatal(err)
	}
	err = ioutil.WriteFile(filepath.Join(rootDir, "response.txt"), []byte("Root response"), 0644)
	if err != nil {
		t.Fatal(err)
	}

	// Create prompt.txt and response.txt in subdir
	err = ioutil.WriteFile(filepath.Join(subDir, "prompt.txt"), []byte("Subdir message"), 0644)
	if err != nil {
		t.Fatal(err)
	}
	err = ioutil.WriteFile(filepath.Join(subDir, "response.txt"), []byte("Subdir response"), 0644)
	if err != nil {
		t.Fatal(err)
	}

	// Call buildContextMessages
	messages := buildContextMessages(subDir)

	// Expected messages
	expectedMessages := []llm.Message{
		{Role: llm.ChatMessageRoleUser, Content: "Root message"},
		{Role: llm.ChatMessageRoleAssistant, Content: "Root response"},
		{Role: llm.ChatMessageRoleUser, Content: "Subdir message"},
		{Role: llm.ChatMessageRoleAssistant, Content: "Subdir response"},
	}

	if len(messages) != len(expectedMessages) {
		t.Fatalf("Expected %d messages, got %d", len(expectedMessages), len(messages))
	}

	for i, msg := range messages {
		if msg.Role != expectedMessages[i].Role || msg.Content != expectedMessages[i].Content {
			t.Errorf("Message %d expected %+v, got %+v", i, expectedMessages[i], msg)
		}
	}
}

func TestGetAttachmentsContent(t *testing.T) {
	// Set up temporary directory
	tempDir, err := ioutil.TempDir("", "test_attachments")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(tempDir)

	// Create attachment.pdf.txt
	attachmentContent := "Extracted text from PDF"
	err = ioutil.WriteFile(filepath.Join(tempDir, "attachment.pdf.txt"), []byte(attachmentContent), 0644)
	if err != nil {
		t.Fatal(err)
	}

	// Call getAttachmentsContent
	content, err := getAttachmentsContent(tempDir)
	if err != nil {
		t.Fatalf("Expected no error, got %v", err)
	}

	expectedContent := "Attachment: attachment.pdf.txt\n" + attachmentContent + "\n"
	if content != expectedContent {
		t.Errorf("Expected content:\n%s\nGot:\n%s", expectedContent, content)
	}
}

func TestGetLLMResponse(t *testing.T) {
	// Create the mock client
	var errClient error
	client, errClient = llm.NewClient("mock-model")
	if errClient != nil {
		t.Fatalf("Error creating mock client: %v", errClient)
	}

	// Mock messages
	messages := []llm.Message{
		{Role: llm.ChatMessageRoleUser, Content: "Hello"},
	}

	// Call getLLMResponse
	response, err := getLLMResponse(messages)
	if err != nil {
		t.Fatalf("Expected no error, got %v", err)
	}

	if response != "This is a mock response." {
		t.Errorf("Expected 'This is a mock response.', got '%s'", response)
	}
}

func TestHandlePDFAttachment(t *testing.T) {
	// Set up temporary directory
	tempDir, err := ioutil.TempDir("", "test_pdf_attachment")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(tempDir)

	// Create a fake PDF file (since we're not testing PDF parsing here)
	pdfPath := filepath.Join(tempDir, "attachment.pdf")
	err = ioutil.WriteFile(pdfPath, []byte("%PDF-1.4 Fake PDF content"), 0644)
	if err != nil {
		t.Fatal(err)
	}

	// Mock extractTextFromPDF function
	mockExtractText := func(pdfPath string) (string, error) {
		return "Extracted text", nil
	}

	// Call handlePDFAttachment
	handlePDFAttachment(pdfPath, mockExtractText)

	// Check if attachment.pdf.txt is created
	txtPath := pdfPath + ".txt"
	data, err := ioutil.ReadFile(txtPath)
	if err != nil {
		t.Fatalf("Expected %s to be created, got error: %v", txtPath, err)
	}

	if string(data) != "Extracted text" {
		t.Errorf("Expected 'Extracted text', got '%s'", string(data))
	}
}

func TestExtractTextFromPDF(t *testing.T) {
	// Since testing actual PDF extraction is complex, we'll test error handling
	// Attempt to extract text from a non-existent PDF
	_, err := extractTextFromPDF("non_existent.pdf")
	if err == nil {
		t.Errorf("Expected error when extracting from non-existent PDF")
	}
}

func TestSummarizePath(t *testing.T) {
	// Set up temporary directory
	tempDir, err := ioutil.TempDir("", "test_summarize")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(tempDir)

	// Create conversation files
	err = ioutil.WriteFile(filepath.Join(tempDir, "prompt.txt"), []byte("User message"), 0644)
	if err != nil {
		t.Fatal(err)
	}
	err = ioutil.WriteFile(filepath.Join(tempDir, "response.txt"), []byte("LLM response"), 0644)
	if err != nil {
		t.Fatal(err)
	}

	// Create the mock client
	var errClient error
	client, errClient = llm.NewClient("mock-model")
	if errClient != nil {
		t.Fatalf("Error creating mock client: %v", errClient)
	}

	// Call summarizePath
	summarizePath(tempDir)

	// Check if summary.txt is created
	summaryPath := filepath.Join(tempDir, "summary.txt")
	data, err := ioutil.ReadFile(summaryPath)
	if err != nil {
		t.Fatalf("Expected summary.txt to be created, got error: %v", err)
	}

	if string(data) != "This is a mock response." {
		t.Errorf("Expected 'This is a mock response.', got '%s'", string(data))
	}
}

func TestUpdateMetrics(t *testing.T) {
	// Set up temporary directory
	tempDir, err := ioutil.TempDir("", "test_metrics")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(tempDir)

	// Define metrics
	metrics := map[string]interface{}{
		"completeness":        0.9,
		"logical_consistency": 0.95,
	}

	// Call updateMetrics
	updateMetrics(tempDir, metrics)

	// Check if metrics.json is created
	metricsPath := filepath.Join(tempDir, "metrics.json")
	data, err := ioutil.ReadFile(metricsPath)
	if err != nil {
		t.Fatalf("Expected metrics.json to be created, got error: %v", err)
	}

	var readMetrics map[string]interface{}
	err = json.Unmarshal(data, &readMetrics)
	if err != nil {
		t.Fatalf("Error unmarshalling metrics.json: %v", err)
	}

	if readMetrics["completeness"] != metrics["completeness"] {
		t.Errorf("Expected completeness %v, got %v", metrics["completeness"], readMetrics["completeness"])
	}

	if readMetrics["logical_consistency"] != metrics["logical_consistency"] {
		t.Errorf("Expected logical_consistency %v, got %v", metrics["logical_consistency"], readMetrics["logical_consistency"])
	}
}

func TestAddWatcherRecursive(t *testing.T) {
	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		t.Fatal(err)
	}
	defer watcher.Close()

	// Set up nested directories
	rootDir, err := ioutil.TempDir("", "test_watcher")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(rootDir)

	subDir := filepath.Join(rootDir, "subdir")
	err = os.Mkdir(subDir, 0755)
	if err != nil {
		t.Fatal(err)
	}

	// Call addWatcherRecursive
	err = addWatcherRecursive(watcher, rootDir)
	if err != nil {
		t.Fatalf("Expected no error, got %v", err)
	}

	// Check if both directories are being watched
	if _, ok := watcher.WatchList()[rootDir]; !ok {
		t.Errorf("Expected rootDir to be in watch list")
	}

	if _, ok := watcher.WatchList()[subDir]; !ok {
		t.Errorf("Expected subDir to be in watch list")
	}
}

func TestGetSummary(t *testing.T) {
	// Create the mock client
	var errClient error
	client, errClient = llm.NewClient("mock-model")
	if errClient != nil {
		t.Fatalf("Error creating mock client: %v", errClient)
	}

	// Call getSummary
	text := "Conversation text"
	summary, err := getSummary(text)
	if err != nil {
		t.Fatalf("Expected no error, got %v", err)
	}

	if summary != "This is a mock response." {
		t.Errorf("Expected 'This is a mock response.', got '%s'", summary)
	}
}

func TestErrorHandlingInHandleUserMessage(t *testing.T) {
	// Use a non-existent directory
	nonExistentPath := "non_existent_dir"

	// Call handleUserMessage
	handleUserMessage(nonExistentPath)

	// Expect no panic and error to be logged
}

func TestErrorHandlingInGetAttachmentsContent(t *testing.T) {
	// Use a non-existent directory
	nonExistentPath := "non_existent_dir"

	// Call getAttachmentsContent
	_, err := getAttachmentsContent(nonExistentPath)
	if err == nil {
		t.Errorf("Expected error when reading attachments from non-existent directory")
	}
}

func TestErrorHandlingInUpdateMetrics(t *testing.T) {
	// Use a read-only directory
	tempDir, err := ioutil.TempDir("", "test_metrics_readonly")
	if err != nil {
		t.Fatal(err)
	}
	defer os.RemoveAll(tempDir)

	// Make directory read-only
	err = os.Chmod(tempDir, 0444)
	if err != nil {
		t.Fatal(err)
	}

	// Define metrics
	metrics := map[string]interface{}{
		"test_metric": 1.0,
	}

	// Call updateMetrics
	updateMetrics(tempDir, metrics)

	// Expect error to be logged
}
```
EOF_/home/stevegt/lab/aidss/cmd/aidss/main_test.go

File: /home/stevegt/lab/aidss/llm/openai.go
```go
package llm

import (
	"context"
	"errors"
	"os"

	openai "github.com/sashabaranov/go-openai"
)

type OpenAI struct {
	client *openai.Client
	model  Model
}

type OpenAIProvider struct {
	apiKey string
}

// Model struct represents a language model with its attributes
type Model struct {
	Name        string
	MaxTokens   int
	Temperature float32
}

// Map of model names to Model structs
var openAIModels = map[string]Model{
	"gpt-3.5-turbo": {
		Name:        "gpt-3.5-turbo",
		MaxTokens:   4096,
		Temperature: 0.7,
	},
	"gpt-4": {
		Name:        "gpt-4",
		MaxTokens:   8192,
		Temperature: 0.7,
	},
}

// NewOpenAIProvider creates a new instance of OpenAIProvider
func NewOpenAIProvider() *OpenAIProvider {
	apiKey := os.Getenv("OPENAI_API_KEY")
	if apiKey == "" {
		// Return nil if API key is not set
		return nil
	}

	return &OpenAIProvider{
		apiKey: apiKey,
	}
}

// NewClient returns a new OpenAI client for the given model
func (p *OpenAIProvider) NewClient(modelName string) (Client, error) {
	model, ok := openAIModels[modelName]
	if !ok {
		return nil, errors.New("unsupported model: " + modelName)
	}

	// Create OpenAI client
	client := openai.NewClient(p.apiKey)

	return &OpenAI{
		client: client,
		model:  model,
	}, nil
}

// Models returns the models available in OpenAI
func (p *OpenAIProvider) Models() []string {
	models := make([]string, 0, len(openAIModels))
	for modelName := range openAIModels {
		models = append(models, modelName)
	}
	return models
}

// GenerateResponse implements the Client interface
func (o *OpenAI) GenerateResponse(ctx context.Context, messages []Message) (string, error) {
	// Convert Messages to openai.ChatCompletionMessage
	var chatMessages []openai.ChatCompletionMessage
	for _, msg := range messages {
		chatMessages = append(chatMessages, openai.ChatCompletionMessage{
			Role:    msg.Role,
			Content: msg.Content,
		})
	}

	// Build the request
	req := openai.ChatCompletionRequest{
		Model:       o.model.Name,
		Messages:    chatMessages,
		MaxTokens:   o.model.MaxTokens,
		Temperature: o.model.Temperature,
	}

	// Call the OpenAI API
	resp, err := o.client.CreateChatCompletion(ctx, req)
	if err != nil {
		return "", err
	}

	return resp.Choices[0].Message.Content, nil
}
```
EOF_/home/stevegt/lab/aidss/llm/openai.go

File: /home/stevegt/lab/aidss/llm/mock.go
```go
package llm

import (
	"context"
)

// Mock implements Client interface
type Mock struct {
	model Model
}

// MockProvider implements Provider interface
type MockProvider struct{}

// Mock model
var mockModel = Model{
	Name:        "mock-model",
	MaxTokens:   1000,
	Temperature: 0.7,
}

// NewMockProvider creates a new instance of MockProvider
func NewMockProvider() *MockProvider {
	return &MockProvider{}
}

// NewClient returns a new Mock client
func (p *MockProvider) NewClient(modelName string) (Client, error) {
	return &Mock{
		model: mockModel,
	}, nil
}

// Models returns the models available in Mock
func (p *MockProvider) Models() []string {
	return []string{mockModel.Name}
}

// GenerateResponse returns a mock response
func (m *Mock) GenerateResponse(ctx context.Context, messages []Message) (string, error) {
	return "This is a mock response.", nil
}
```
EOF_/home/stevegt/lab/aidss/llm/mock.go

File: /home/stevegt/lab/aidss/llm/llm.go
```go
package llm

import (
	"context"
	"fmt"
	"sync"
)

// Message represents a chat message.
type Message struct {
	Role    string // e.g., "user", "assistant", "system"
	Content string
}

// Define constants for message roles
const (
	ChatMessageRoleUser      = "user"
	ChatMessageRoleAssistant = "assistant"
	ChatMessageRoleSystem    = "system"
)

// Client is the interface that all LLM clients must implement.
type Client interface {
	GenerateResponse(ctx context.Context, messages []Message) (string, error)
}

// Provider represents an LLM provider.
type Provider interface {
	// NewClient returns a new Client instance for the given model name
	NewClient(modelName string) (Client, error)
	// Models returns a list of model names supported by this provider.
	Models() []string
}

var (
	// Mutex for thread-safe access to the provider registry.
	registryMutex sync.Mutex
	// Map of provider names to Provider instances.
	providers = make(map[string]Provider)
	// Map of model names to provider names.
	modelToProvider = make(map[string]string)
)

// RegisterProvider registers a provider with the llm package.
func RegisterProvider(providerName string, provider Provider) {
	registryMutex.Lock()
	defer registryMutex.Unlock()

	providers[providerName] = provider
	for _, model := range provider.Models() {
		modelToProvider[model] = providerName
	}
}

// Models returns all models from all registered providers.
func Models() []string {
	registryMutex.Lock()
	defer registryMutex.Unlock()

	models := make([]string, 0, len(modelToProvider))
	for model := range modelToProvider {
		models = append(models, model)
	}
	return models
}

// NewClient returns a Client for the given model name.
func NewClient(modelName string) (Client, error) {
	registryMutex.Lock()
	defer registryMutex.Unlock()

	providerName, ok := modelToProvider[modelName]
	if !ok {
		return nil, fmt.Errorf("model %s not supported", modelName)
	}
	provider, ok := providers[providerName]
	if !ok {
		return nil, fmt.Errorf("provider %s not found for model %s", providerName, modelName)
	}
	return provider.NewClient(modelName)
}

func RegisterProviders() {
	// Initialize and register providers
	openAIProvider := NewOpenAIProvider()
	if openAIProvider != nil {
		RegisterProvider("openai", openAIProvider)
	}
	// more providers can be added here

	// Register a mock provider for testing
	mockProvider := NewMockProvider()
	RegisterProvider("mock", mockProvider)
}
```
EOF_/home/stevegt/lab/aidss/llm/llm.go